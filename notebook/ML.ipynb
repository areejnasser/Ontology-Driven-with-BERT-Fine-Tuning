{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pMByBLx8nHR"
      },
      "source": [
        "## Import dependancies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6VaX2I8F2bx",
        "outputId": "fdcde4a5-bb5a-4298-a23b-41833d1e1aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RLJvJ0wGuEX",
        "outputId": "cfa241ce-ab05-4fe8-a742-8cb93c8ef393"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgJNbX4870OG",
        "outputId": "366166b9-aa15-400e-bd55-994e3646ccc4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "#for import the data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# for the visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#for the text pre-processing (text cleaning)\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re #regular expression\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize # word tokenization\n",
        "from nltk.stem import PorterStemmer # word stemming\n",
        "\n",
        "#for feature extraction ( vectorazation)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#for split the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#for the model training\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#for the model evaluation\n",
        "from sklearn.metrics import multilabel_confusion_matrix,classification_report\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import contractions\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcmmNC7Q70Qb"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ijdo8rf8rD0"
      },
      "source": [
        "## Import and preprocess dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDGLcDgb70TT"
      },
      "outputs": [],
      "source": [
        "#Data with negative sample (without annotation)\n",
        "data_N = pd.read_csv('/content/drive/MyDrive/post classification/processed_data/posts_with_Label_and_without_preflable.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gANJ2luC3Kpw"
      },
      "outputs": [],
      "source": [
        "#Data with ontology and manual label\n",
        "df = pd.read_csv('/content/drive/MyDrive/post classification/processed_data/posts-ontology-manual-label.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIjmzsFe70Vj",
        "outputId": "f86c34e0-91ca-448d-9de8-50e1a6028665"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9497, 4)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7BSyiH5EK-K"
      },
      "outputs": [],
      "source": [
        "data_N.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0G5d74y4Agp"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcaqYs9T70X9"
      },
      "outputs": [],
      "source": [
        "# defne new column named 'email_length' that contain the length of each email in the dataset\n",
        "data_N[\"post_length\"]=data_N[\"post\"].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHJz_RVu70cI",
        "outputId": "f8c4b1e7-d50a-435a-c791-0ef4279e19e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the max length post is: 9985\n",
            "the min length post is: 1\n",
            "the avg length post is: 1145.9829419816783\n"
          ]
        }
      ],
      "source": [
        "print('the max length post is:',data_N['post_length'].max())\n",
        "print('the min length post is:',data_N['post_length'].min())\n",
        "print('the avg length post is:',data_N['post_length'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNp1M5xX70ny"
      },
      "outputs": [],
      "source": [
        "# delete all emails that its length not in [2500:10]\n",
        "data_N = data_N[data_N.post_length<2000]\n",
        "data_N = data_N[data_N.post_length>6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrbNxNYjEjCK",
        "outputId": "c68bd473-5e05-4e3a-dbc5-51a4e2b87c7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7959\n"
          ]
        }
      ],
      "source": [
        "print(len(data_N))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5fV6TX43mmy"
      },
      "outputs": [],
      "source": [
        "# Check for NaN values and replace them with an empty string\n",
        "df['post'] = df['post'].fillna('')\n",
        "\n",
        "# Define a new column named 'post_length' that contains the length of each post in the dataset\n",
        "df['post_length'] = df['post'].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw-h9K543u75",
        "outputId": "a89bf5f8-a3ef-434a-92c9-f7ab05d252ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the max length post is: 10013\n",
            "the min length post is: 0\n",
            "the avg length post is: 1139.6069427771108\n"
          ]
        }
      ],
      "source": [
        "print('the max length post is:',df['post_length'].max())\n",
        "print('the min length post is:',df['post_length'].min())\n",
        "print('the avg length post is:',df['post_length'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ClJTEGdDfl4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "#define the process of text cleaning\n",
        "def deEmojify(text):\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r' ',text)\n",
        "#Clean Text\n",
        "def clean_text(data):\n",
        "    # convert catacter to lowercase\n",
        "    data['clean_text']=data['post'].str.lower()\n",
        "    #remove URLS\n",
        "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"http\\S+\", \"\", elem))\n",
        "    #remove ponctuation\n",
        "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"[^\\w\\s]\", \"\", elem))\n",
        "    #remove\n",
        "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'/n',\"\",elem))\n",
        "    #remove degits\n",
        "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\d+',\"\",elem))\n",
        "    #remove emojis\n",
        "    data['clean_text'] = data['clean_text'].apply(lambda elem:deEmojify(elem))\n",
        "    #remove multiple spaces\n",
        "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+',\" \",elem))\n",
        "    #remove single caracter\n",
        "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+[a-zA-Z]\\s+',\" \",elem))\n",
        "    return data\n",
        "\n",
        "\n",
        "def process_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Handle contractions using the contractions library\n",
        "    expanded_text = contractions.fix(text)\n",
        "\n",
        "    # Lowercasing\n",
        "    expanded_text = expanded_text.lower()\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(expanded_text)\n",
        "\n",
        "    # Removing Punctuation\n",
        "    tokens = [word for word in tokens if word.isalnum()]\n",
        "\n",
        "    # Removing Stop Words\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatization\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj-CL7Dv8Tbt"
      },
      "outputs": [],
      "source": [
        "process_df = df.copy()\n",
        "process_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrR90yTqFHe-"
      },
      "outputs": [],
      "source": [
        "#apply the process of cleaning for the train and test data\n",
        "process_df = clean_text(process_df)\n",
        "process_df['post'] = process_df['post'].apply(process_text)\n",
        "#process_df['clean_text'] = process_df['clean_text'].apply(process_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aP0_8ew7L8o"
      },
      "outputs": [],
      "source": [
        "process_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YR5Y79N67iC",
        "outputId": "d92ccdf2-9cb2-44aa-b1a7-bb36748eceba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of posts: 9996\n",
            "Number of '1's in 'obsession' column: 5029\n",
            "Number of '1's in 'compulsion' column: 2702\n",
            "Number of '0's in 'obsession' column: 4967\n",
            "Number of '0's in 'compulsion' column: 7294\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'process_df' is the DataFrame name\n",
        "# Print the number of posts\n",
        "print(f\"Number of posts: {len(process_df)}\")\n",
        "\n",
        "# Print the count of '1' in the 'obsession' column\n",
        "print(f\"Number of '1's in 'obsession' column: {process_df['obsession'].sum()}\")\n",
        "print(f\"Number of '1's in 'compulsion' column: {process_df['compulsion'].sum()}\")\n",
        "\n",
        "# Print the count of '0's in both 'obsession' and 'compulsion' columns\n",
        "print(f\"Number of '0's in 'obsession' column: {len(process_df) - process_df['obsession'].sum()}\")\n",
        "print(f\"Number of '0's in 'compulsion' column: {len(process_df) - process_df['compulsion'].sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLbJKawVBaRq"
      },
      "source": [
        "## BOW and splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VyFrgyu8TiY"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Creating features using Bag of Words\n",
        "text_data = process_df['post'].astype(str)\n",
        "\n",
        "# Convert text to vectors using CountVectorizer with specified parameters\n",
        "count_vect = CountVectorizer(max_features=25000, min_df=5, max_df=0.9, stop_words='english')\n",
        "X = count_vect.fit_transform(text_data)\n",
        "\n",
        "# Assuming 'compulsion' and 'obsession' are the target labels\n",
        "Y = np.asarray(process_df[['compulsion', 'obsession']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnIu8Bbv70qc",
        "outputId": "c5254287-72e3-4030-de4f-6d2c9108f7e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents: 9996\n",
            "Number of unique tokens: 7281\n"
          ]
        }
      ],
      "source": [
        "# Get the shape (size) of the DTM\n",
        "num_documents, num_tokens = X.shape\n",
        "\n",
        "# Print the number of documents and tokens\n",
        "print(\"Number of documents:\", num_documents)\n",
        "print(\"Number of unique tokens:\", num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG4oY4xN8vqX",
        "outputId": "5407e895-8a3f-49ff-a0b9-96fc12ae6c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9996, 7281)\n",
            "(9996, 2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmYD6spZ8vv_"
      },
      "outputs": [],
      "source": [
        "# Assuming X and Y are your feature and target variables\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngsHIaSVJ8MA",
        "outputId": "b4c0f6f9-85b8-4c0a-d8db-b84c826db29f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7996, 7281)\n",
            "(2000, 7281)\n",
            "(7996, 2)\n",
            "(2000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYByN9PuLwB6"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7IMii_-Ly6i",
        "outputId": "f96444f3-45cc-42cd-ac24-375cb257761f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix for obsession:\n",
            "[[1419    3]\n",
            " [ 173  405]]\n",
            "\n",
            "\n",
            "Confusion Matrix for compulsion:\n",
            "[[845 151]\n",
            " [ 15 989]]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "conf_matrix = multilabel_confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Print confusion matrix for each class\n",
        "for i, label in enumerate(['obsession', 'compulsion']):\n",
        "    print(f\"Confusion Matrix for {label}:\")\n",
        "    print(conf_matrix[i])\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POBXHxxsQzP7",
        "outputId": "d2efd0a2-2a72-4efe-d6d3-b65c27883c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for obsession: 0.912\n",
            "Accuracy for compulsion: 0.917\n"
          ]
        }
      ],
      "source": [
        "# Assuming y_test and y_pred are your actual and predicted labels\n",
        "label_names = ['obsession', 'compulsion']\n",
        "\n",
        "# Calculate accuracy for each label\n",
        "accuracy_per_label = {label: accuracy_score(y_test[:, i], y_pred_rf[:, i]) for i, label in enumerate(label_names)}\n",
        "\n",
        "# Print accuracy for each label\n",
        "for label, acc in accuracy_per_label.items():\n",
        "    print(f'Accuracy for {label}: {acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk5eF-LeLzA6",
        "outputId": "5bf32aa4-bdb2-467a-c51f-7fd02c47b92a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   obsession       0.99      0.70      0.82       578\n",
            "  compulsion       0.87      0.99      0.92      1004\n",
            "\n",
            "   micro avg       0.90      0.88      0.89      1582\n",
            "   macro avg       0.93      0.84      0.87      1582\n",
            "weighted avg       0.91      0.88      0.89      1582\n",
            " samples avg       0.61      0.61      0.61      1582\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#classification report\n",
        "label_names = ['obsession','compulsion']\n",
        "report = classification_report(y_test, y_pred_rf, target_names=label_names)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnSvIQdOLzL2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y6j9f5NYsIV"
      },
      "source": [
        "## Prediction on manual label data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh6zBAHB89VY"
      },
      "outputs": [],
      "source": [
        "unlabed_data = pd.read_csv('/content/drive/MyDrive/post classification/manual_check/manual-check-small-data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK0R5817-2JK"
      },
      "outputs": [],
      "source": [
        "unlabed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2D8A8mh-kHm"
      },
      "outputs": [],
      "source": [
        "#import model\n",
        "import joblib\n",
        "#clf = joblib.load('../model/RFModel.pkl')\n",
        "LR_BOW = joblib.load(\"/content/drive/MyDrive/post classification/model/ml_model/LR_BOW.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjU-9hGpVhun"
      },
      "outputs": [],
      "source": [
        "#apply the process of cleaning for the train and test data\n",
        "unlabed_data = clean_text(unlabed_data)\n",
        "unlabed_data['post'] = unlabed_data['post'].apply(process_text)\n",
        "#process_df['clean_text'] = process_df['clean_text'].apply(process_text)\n",
        "unlabed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKeH9Wml-kT6"
      },
      "outputs": [],
      "source": [
        "# Assuming 'clean_text' is the column containing text data\n",
        "unlabeled_data_text = unlabed_data['post']\n",
        "\n",
        "# Transform the unlabelled data using the same CountVectorizer\n",
        "X1 = count_vect.transform(unlabeled_data_text)\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "predictions = clf_LR.predict(X1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiO44v98-kWw"
      },
      "outputs": [],
      "source": [
        "# Assuming 'predictions' is a NumPy array or Pandas DataFrame containing the predicted labels\n",
        "# Add these predictions to your unlabeled data or save them as needed\n",
        "unlabed_data['predicted_compulsion'] = predictions[:, 0]\n",
        "unlabed_data['predicted_obsession'] = predictions[:, 1]\n",
        "\n",
        "# Display or save the results\n",
        "print(unlabed_data[['post', 'predicted_compulsion', 'predicted_obsession']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cTqoo-UHqKW",
        "outputId": "a99ae07f-4aa8-45b8-b38e-fb60a47a17d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation for 'obsession':\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.98      0.78       300\n",
            "         1.0       0.44      0.02      0.04       170\n",
            "\n",
            "    accuracy                           0.64       470\n",
            "   macro avg       0.54      0.50      0.41       470\n",
            "weighted avg       0.57      0.64      0.51       470\n",
            "\n",
            "\n",
            "Evaluation for 'compulsion':\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      0.85      0.88       420\n",
            "         1.0       0.18      0.28      0.22        50\n",
            "\n",
            "    accuracy                           0.79       470\n",
            "   macro avg       0.55      0.56      0.55       470\n",
            "weighted avg       0.83      0.79      0.81       470\n",
            "\n",
            "\n",
            "Accuracy for 'obsession': 0.6361702127659574\n",
            "Accuracy for 'compulsion': 0.7893617021276595\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Assuming 'clean_text' is the column containing text data\n",
        "unlabeled_data_vec_first_470 = count_vect.transform(unlabed_data['post'].head(470))\n",
        "\n",
        "# Make predictions using the loaded model for the first 470 rows\n",
        "predictions_first_470 = LR_BOW.predict(unlabeled_data_vec_first_470)\n",
        "\n",
        "# Assuming unlabeled_data is your DataFrame for the first 470 rows\n",
        "# Replace '...' with your actual DataFrame variable\n",
        "unlabeled_data_first_470 = unlabed_data.head(470)\n",
        "\n",
        "# Replace NaN values in the manual labels with 0 (you can choose a different approach)\n",
        "y_true_first_470 = unlabeled_data_first_470[['obsession_first_checker', 'compulsion_first_checker']].fillna(0).values\n",
        "\n",
        "# Evaluate the model on the first 470 rows\n",
        "print(\"\\nEvaluation for 'obsession':\")\n",
        "print(classification_report(y_true_first_470[:, 0], predictions_first_470[:, 0]))\n",
        "\n",
        "print(\"\\nEvaluation for 'compulsion':\")\n",
        "print(classification_report(y_true_first_470[:, 1], predictions_first_470[:, 1]))\n",
        "\n",
        "# Print accuracy\n",
        "print(\"\\nAccuracy for 'obsession':\", accuracy_score(y_true_first_470[:, 0], predictions_first_470[:, 0]))\n",
        "print(\"Accuracy for 'compulsion':\", accuracy_score(y_true_first_470[:, 1], predictions_first_470[:, 1]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcjil55yDNr3"
      },
      "outputs": [],
      "source": [
        "unlabed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgHgbejcFD3e",
        "outputId": "2d92bd34-89fb-4f52-8036-1fb15dbe3e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Manual Label Counts for 'obsession':\n",
            "Label 0: 321\n",
            "Label 1: 176\n",
            "\n",
            "Manual Label Counts for 'compulsion':\n",
            "Label 0: 446\n",
            "Label 1: 51\n",
            "\n",
            "Predicted Label Counts for 'obsession':\n",
            "Label 0: 447\n",
            "Label 1: 52\n",
            "\n",
            "Predicted Label Counts for 'compulsion':\n",
            "Label 0: 489\n",
            "Label 1: 10\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Assuming df is your DataFrame containing the mentioned columns\n",
        "# Replace this line with your actual DataFrame\n",
        "df = ...\n",
        "\n",
        "# Extract the true labels (manual labels) and predicted labels\n",
        "y_true = unlabed_data[['obsession_first_checker', 'compulsion_first_checker']].values\n",
        "y_pred = unlabed_data[['predicted_obsession', 'predicted_compulsion']].values\n",
        "\n",
        "# Evaluate the model on the first 470 posts (exclude rows without manual labels)\n",
        "mask = ~unlabed_data['obsession_first_checker'].isnull()\n",
        "y_true_sub = y_true[mask]\n",
        "y_pred_sub = y_pred[mask]\n",
        "\n",
        "# Count the number of manual labels for 'obsession'\n",
        "obsession_manual_counts = unlabed_data['obsession_first_checker'].value_counts().to_dict()\n",
        "print(\"\\nManual Label Counts for 'obsession':\")\n",
        "print(\"Label 0:\", obsession_manual_counts.get(0, 0))\n",
        "print(\"Label 1:\", obsession_manual_counts.get(1, 0))\n",
        "\n",
        "# Count the number of manual labels for 'compulsion'\n",
        "compulsion_manual_counts = unlabed_data['compulsion_first_checker'].value_counts().to_dict()\n",
        "print(\"\\nManual Label Counts for 'compulsion':\")\n",
        "print(\"Label 0:\", compulsion_manual_counts.get(0, 0))\n",
        "print(\"Label 1:\", compulsion_manual_counts.get(1, 0))\n",
        "\n",
        "# Count the number of predicted labels for 'obsession'\n",
        "obsession_pred_counts = unlabed_data['predicted_obsession'].value_counts().to_dict()\n",
        "print(\"\\nPredicted Label Counts for 'obsession':\")\n",
        "print(\"Label 0:\", obsession_pred_counts.get(0, 0))\n",
        "print(\"Label 1:\", obsession_pred_counts.get(1, 0))\n",
        "\n",
        "# Count the number of predicted labels for 'compulsion'\n",
        "compulsion_pred_counts = unlabed_data['predicted_compulsion'].value_counts().to_dict()\n",
        "print(\"\\nPredicted Label Counts for 'compulsion':\")\n",
        "print(\"Label 0:\", compulsion_pred_counts.get(0, 0))\n",
        "print(\"Label 1:\", compulsion_pred_counts.get(1, 0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IyzJxusDzLH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8zfL9ZQLtJC"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s--kDI2fJZ3M"
      },
      "source": [
        "## NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "miM_r96BNhEd",
        "outputId": "85f2e444-e089-4f30-a942-093dff7afb52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=MultinomialNB())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=MultinomialNB())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "MultiOutputClassifier(estimator=MultinomialNB())"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#intialize the Random Forest Model\n",
        "clf_NB = MultiOutputClassifier(MultinomialNB()).fit(X_train, y_train)\n",
        "#train the model\n",
        "clf_NB.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YheXCBqANhJM"
      },
      "outputs": [],
      "source": [
        "prediction_NB= clf_NB.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvTonBZFQKRJ",
        "outputId": "df42055c-ea6f-4021-ff70-0b5362d28f94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       ...,\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 0]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction_NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT9eCmNcQV6A",
        "outputId": "70736d06-627c-438a-f0dc-6c6181a517a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   obsession       0.70      0.79      0.74       578\n",
            "  compulsion       0.77      0.88      0.82      1004\n",
            "\n",
            "   micro avg       0.74      0.85      0.79      1582\n",
            "   macro avg       0.73      0.84      0.78      1582\n",
            "weighted avg       0.74      0.85      0.79      1582\n",
            " samples avg       0.56      0.59      0.56      1582\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#classification report\n",
        "label_names = ['obsession','compulsion']\n",
        "print(classification_report(y_test, prediction_NB,target_names=label_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFLRAGi4Dzrr",
        "outputId": "ad7f7277-437e-4871-cbb0-bc08e707ab29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[[1260  162]\n",
            "  [ 153  425]]\n",
            "\n",
            " [[ 647  349]\n",
            "  [  87  917]]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# Print confusion matrix\n",
        "# Print confusion matrix\n",
        "conf_matrix = multilabel_confusion_matrix(y_test, prediction_NB)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "#For the 'obsession' class:\n",
        "#True Positive (TP): 425\n",
        "#False Positive (FP): 162\n",
        "#True Negative (TN): 1260\n",
        "#False Negative (FN): 153\n",
        "\n",
        "#For the 'compulsion' class:\n",
        "#True Positive (TP): 917\n",
        "#False Positive (FP): 349\n",
        "#True Negative (TN): 647\n",
        "#False Negative (FN): 87\n",
        "\n",
        "\n",
        "#True Positive (TP): Instances correctly predicted as belonging to the class.\n",
        "#False Positive (FP): Instances incorrectly predicted as belonging to the class (they don't actually belong to it).\n",
        "#True Negative (TN): Instances correctly predicted as not belonging to the class.\n",
        "#False Negative (FN): Instances incorrectly predicted as not belonging to the class (they actually belong to it).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC1RdTPDOGDD",
        "outputId": "15fe3558-8d67-485c-b06e-46d0600eb97a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6935\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, prediction_NB)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Xrx5kng7rzx",
        "outputId": "409e2e24-b7e1-4115-aecb-5bcf5ab03df6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for obsession: 0.8425\n",
            "Accuracy for compulsion: 0.808\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Assuming y_test and y_pred are your actual and predicted labels\n",
        "label_names = ['obsession', 'compulsion']\n",
        "\n",
        "# Calculate accuracy for each label\n",
        "accuracy_per_label = {label: accuracy_score(y_test[:, i], prediction_NB[:, i]) for i, label in enumerate(label_names)}\n",
        "\n",
        "# Print accuracy for each label\n",
        "for label, acc in accuracy_per_label.items():\n",
        "    print(f'Accuracy for {label}: {acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R_yP1UeDqoD"
      },
      "source": [
        "## Prediction on manual label using NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrAkuSSMQopQ",
        "outputId": "fb53868e-4332-41e9-97fe-98ddfe31d7e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation for 'obsession':\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.90      0.75       300\n",
            "         1.0       0.37      0.11      0.16       170\n",
            "\n",
            "    accuracy                           0.61       470\n",
            "   macro avg       0.50      0.50      0.46       470\n",
            "weighted avg       0.54      0.61      0.54       470\n",
            "\n",
            "\n",
            "Evaluation for 'compulsion':\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.39      0.54       420\n",
            "         1.0       0.10      0.58      0.17        50\n",
            "\n",
            "    accuracy                           0.41       470\n",
            "   macro avg       0.49      0.49      0.36       470\n",
            "weighted avg       0.80      0.41      0.50       470\n",
            "\n",
            "\n",
            "Accuracy for 'obsession': 0.6106382978723405\n",
            "Accuracy for 'compulsion': 0.4106382978723404\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'clean_text' is the column containing text data\n",
        "unlabeled_data_vec_first_470 = count_vect.transform(unlabed_data['clean_text'].head(470))\n",
        "\n",
        "# Make predictions using the loaded model for the first 470 rows\n",
        "predictions_first_470 = clf_NB.predict(unlabeled_data_vec_first_470)\n",
        "\n",
        "# Assuming unlabeled_data is your DataFrame for the first 470 rows\n",
        "# Replace '...' with your actual DataFrame variable\n",
        "unlabeled_data_first_470 = unlabed_data.head(470)\n",
        "\n",
        "# Replace NaN values in the manual labels with 0 (you can choose a different approach)\n",
        "y_true_first_470 = unlabeled_data_first_470[['obsession_first_checker', 'compulsion_first_checker']].fillna(0).values\n",
        "\n",
        "# Evaluate the model on the first 470 rows\n",
        "print(\"\\nEvaluation for 'obsession':\")\n",
        "print(classification_report(y_true_first_470[:, 0], predictions_first_470[:, 0]))\n",
        "\n",
        "print(\"\\nEvaluation for 'compulsion':\")\n",
        "print(classification_report(y_true_first_470[:, 1], predictions_first_470[:, 1]))\n",
        "\n",
        "# Print accuracy\n",
        "print(\"\\nAccuracy for 'obsession':\", accuracy_score(y_true_first_470[:, 0], predictions_first_470[:, 0]))\n",
        "print(\"Accuracy for 'compulsion':\", accuracy_score(y_true_first_470[:, 1], predictions_first_470[:, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKIzhayVRoDG"
      },
      "source": [
        "## K-Nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDEAvN2WRodM",
        "outputId": "9e536fce-de03-41dc-b743-b57b55217780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for KNN: 0.5595\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the KNN model with specified parameters\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto')\n",
        "\n",
        "# Train the KNN model\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "knn_predictions = knn_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, knn_predictions)\n",
        "\n",
        "print(f'Accuracy for KNN: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j0NLJqNRogQ",
        "outputId": "061f50d4-b66f-429c-e92a-944ff34cc2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   obsession       0.84      0.20      0.33       578\n",
            "  compulsion       0.87      0.56      0.68      1004\n",
            "\n",
            "   micro avg       0.87      0.43      0.57      1582\n",
            "   macro avg       0.86      0.38      0.50      1582\n",
            "weighted avg       0.86      0.43      0.55      1582\n",
            " samples avg       0.32      0.30      0.30      1582\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#classification report\n",
        "label_names = ['obsession','compulsion']\n",
        "print(classification_report(y_test, knn_predictions,target_names=label_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5tROXZeFDVg",
        "outputId": "6966a747-99ec-431f-d2c3-7d8c0340d2b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[[1399   23]\n",
            "  [ 460  118]]\n",
            "\n",
            " [[ 916   80]\n",
            "  [ 445  559]]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# Print confusion matrix\n",
        "# Print confusion matrix\n",
        "conf_matrix = multilabel_confusion_matrix(y_test, knn_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "#For the 'obsession' class:\n",
        "#True Positive (TP): 101\n",
        "#False Positive (FP): 39\n",
        "#True Negative (TN): 1383\n",
        "#False Negative (FN): 477\n",
        "\n",
        "#For the 'compulsion' class:\n",
        "#True Positive (TP): 511\n",
        "#False Positive (FP): 75\n",
        "#True Negative (TN): 921\n",
        "#False Negative (FN): 493\n",
        "\n",
        "\n",
        "#True Positive (TP): Instances correctly predicted as belonging to the class.\n",
        "#False Positive (FP): Instances incorrectly predicted as belonging to the class (they don't actually belong to it).\n",
        "#True Negative (TN): Instances correctly predicted as not belonging to the class.\n",
        "#False Negative (FN): Instances incorrectly predicted as not belonging to the class (they actually belong to it).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0cfwOgj9xzq",
        "outputId": "e3fad90f-3b3b-4219-9266-73345ed819e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for obsession: 0.7585\n",
            "Accuracy for compulsion: 0.7375\n"
          ]
        }
      ],
      "source": [
        "# Assuming y_test and y_pred are your actual and predicted labels\n",
        "label_names = ['obsession', 'compulsion']\n",
        "\n",
        "# Calculate accuracy for each label\n",
        "accuracy_per_label = {label: accuracy_score(y_test[:, i], knn_predictions[:, i]) for i, label in enumerate(label_names)}\n",
        "\n",
        "# Print accuracy for each label\n",
        "for label, acc in accuracy_per_label.items():\n",
        "    print(f'Accuracy for {label}: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCuLIIhWOXbm",
        "outputId": "52496f14-2b51-4933-b8c5-0981ce5383ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5595\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, knn_predictions)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuZwTLKgXWhE"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yRBExf4Xd4q"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=3000, max_df=0.9)  # Adjust max_features as needed\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(process_df['post'])\n",
        "\n",
        "\n",
        "# Assuming 'compulsion' and 'obsession' are the target labels\n",
        "y = np.asarray(process_df[['compulsion', 'obsession']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUM0bDo8XeI2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFA6HV7VIGKV"
      },
      "source": [
        "## Logistic regression using tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PAtg7M_Hlgz"
      },
      "outputs": [],
      "source": [
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Re-fit the MultiOutputClassifier\n",
        "clf_LR_tf = MultiOutputClassifier(LogisticRegression()).fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Example prediction\n",
        "y_pred_tf = clf_LR_tf.predict(X_test_tfidf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBT4ywDLIL03",
        "outputId": "6bc00645-c69b-4066-f771-c2850ed65f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   obsession       0.99      0.72      0.83       578\n",
            "  compulsion       0.92      0.93      0.92      1004\n",
            "\n",
            "   micro avg       0.94      0.85      0.89      1582\n",
            "   macro avg       0.95      0.82      0.88      1582\n",
            "weighted avg       0.94      0.85      0.89      1582\n",
            " samples avg       0.60      0.60      0.59      1582\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "label_names = ['obsession','compulsion']\n",
        "print(classification_report(y_test, y_pred_tf,target_names=label_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXfK6dGkFR7f",
        "outputId": "9509d62a-0123-45ee-d094-8ec40bad4fad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[[1417    5]\n",
            "  [ 162  416]]\n",
            "\n",
            " [[ 911   85]\n",
            "  [  72  932]]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# Print confusion matrix\n",
        "# Print confusion matrix\n",
        "conf_matrix = multilabel_confusion_matrix(y_test, y_pred_tf)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "#For the 'obsession' class:\n",
        "#True Positive (TP): 511\n",
        "#False Positive (FP): 28\n",
        "#True Negative (TN): 1394\n",
        "#False Negative (FN): 67\n",
        "\n",
        "#For the 'compulsion' class:\n",
        "#True Positive (TP): 968\n",
        "#False Positive (FP): 35\n",
        "#True Negative (TN): 961\n",
        "#False Negative (FN): 36\n",
        "\n",
        "\n",
        "#True Positive (TP): Instances correctly predicted as belonging to the class.\n",
        "#False Positive (FP): Instances incorrectly predicted as belonging to the class (they don't actually belong to it).\n",
        "#True Negative (TN): Instances correctly predicted as not belonging to the class.\n",
        "#False Negative (FN): Instances incorrectly predicted as not belonging to the class (they actually belong to it).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAI781-kAQe-",
        "outputId": "61dd1bcc-de6e-42f2-a42b-cd7063675b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for obsession: 0.9165\n",
            "Accuracy for compulsion: 0.9215\n"
          ]
        }
      ],
      "source": [
        "# Assuming y_test and y_pred are your actual and predicted labels\n",
        "label_names = ['obsession', 'compulsion']\n",
        "\n",
        "# Calculate accuracy for each label\n",
        "accuracy_per_label = {label: accuracy_score(y_test[:, i], y_pred_tf[:, i]) for i, label in enumerate(label_names)}\n",
        "\n",
        "# Print accuracy for each label\n",
        "for label, acc in accuracy_per_label.items():\n",
        "    print(f'Accuracy for {label}: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7zug0c1OmyS",
        "outputId": "336f9e67-8ba6-494e-9f07-0452fe9575d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.854\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_tf)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgZZaZXVKD2I",
        "outputId": "5ab9bc68-0bae-460f-e960-95eb04a6def1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Save the model and TF-IDF vectorizer\n",
        "joblib.dump(clf_LR_tf, 'model_LR_tf.pkl')\n",
        "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7Gae4hYKJhZ"
      },
      "outputs": [],
      "source": [
        "# Load the TF-IDF vectorizer\n",
        "tfidf_vectorizer_loaded = joblib.load('tfidf_vectorizer.pkl')\n",
        "\n",
        "# Transform the unlabeled data using the loaded TF-IDF vectorizer\n",
        "unlabeled_data_tf = tfidf_vectorizer_loaded.transform(unlabed_data['clean_text'])\n",
        "\n",
        "# Load the trained model\n",
        "clf_LR_tf_loaded = joblib.load('model_LR_tf.pkl')\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "predictions = clf_LR_tf_loaded.predict(unlabeled_data_tf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXeYxaEHNgFf",
        "outputId": "f9103379-2a76-4b3e-cdc3-419c988db80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples for 'y_true_obsession': 497\n",
            "Number of samples for 'predictions[:, 0]': 499\n"
          ]
        }
      ],
      "source": [
        "# Load the manual labels for 'obsession' and 'compulsion'\n",
        "y_true_obsession = unlabed_data['obsession_first_checker']\n",
        "y_true_compulsion = unlabed_data['compulsion_first_checker']\n",
        "\n",
        "# Drop rows with NaN values in the 'obsession_first_checker' column\n",
        "y_true_obsession = y_true_obsession.dropna()\n",
        "\n",
        "# Drop corresponding rows with NaN values in the 'compulsion_first_checker' column\n",
        "y_true_compulsion = y_true_compulsion.dropna()\n",
        "\n",
        "\n",
        "# Print the number of samples for investigation\n",
        "print(\"Number of samples for 'y_true_obsession':\", len(y_true_obsession))\n",
        "print(\"Number of samples for 'predictions[:, 0]':\", len(predictions[:, 0]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diC-TV6fS18X",
        "outputId": "76c7e07b-0380-4a24-a3a0-8fee8f75fea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples for 'y_true_obsession': 499\n",
            "Number of samples for 'predictions[:, 0]': 499\n",
            "Updated number of samples for 'y_true_obsession': 497\n",
            "Updated number of samples for 'predictions_obsession': 497\n"
          ]
        }
      ],
      "source": [
        "# Load the manual labels for 'obsession' and 'compulsion'\n",
        "y_true_obsession = unlabed_data['obsession_first_checker']\n",
        "y_true_compulsion = unlabed_data['compulsion_first_checker']\n",
        "\n",
        "# Print the number of samples for investigation\n",
        "print(\"Number of samples for 'y_true_obsession':\", len(y_true_obsession))\n",
        "print(\"Number of samples for 'predictions[:, 0]':\", len(predictions[:, 0]))\n",
        "\n",
        "# Drop rows with NaN values in 'obsession_first_checker'\n",
        "y_true_obsession = y_true_obsession.dropna()\n",
        "y_true_compulsion = y_true_compulsion.dropna()\n",
        "\n",
        "# Ensure that 'predictions[:, 0]' has the same length as 'y_true_obsession'\n",
        "predictions_obsession = predictions[:len(y_true_obsession), 0]\n",
        "predictions_compulsion= predictions[:len(y_true_compulsion), 0]\n",
        "\n",
        "# Print the updated number of samples for investigation\n",
        "print(\"Updated number of samples for 'y_true_obsession':\", len(y_true_obsession))\n",
        "print(\"Updated number of samples for 'predictions_obsession':\", len(predictions_obsession))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGf6ZglnTP8d",
        "outputId": "b1f2a80a-1ac2-433f-b249-890c1596b78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation for 'obsession':\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.98      0.78       321\n",
            "         1.0       0.29      0.01      0.02       176\n",
            "\n",
            "    accuracy                           0.64       497\n",
            "   macro avg       0.47      0.50      0.40       497\n",
            "weighted avg       0.52      0.64      0.51       497\n",
            "\n",
            "\n",
            "Evaluation for 'compulsion':\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.99      0.94       446\n",
            "         1.0       0.14      0.02      0.03        51\n",
            "\n",
            "    accuracy                           0.89       497\n",
            "   macro avg       0.52      0.50      0.49       497\n",
            "weighted avg       0.82      0.89      0.85       497\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate the predictions for 'obsession'\n",
        "print(\"\\nEvaluation for 'obsession':\")\n",
        "print(classification_report(y_true_obsession, predictions_obsession))\n",
        "\n",
        "print(\"\\nEvaluation for 'compulsion':\")\n",
        "print(classification_report(y_true_compulsion, predictions_compulsion))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfrqJY1sItQN"
      },
      "source": [
        "## Gradient Boosting using tf-idf:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNXQqLXpIpVa"
      },
      "outputs": [],
      "source": [
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initialize the Gradient Boosting model\n",
        "gb_model = GradientBoostingClassifier()\n",
        "\n",
        "# Wrap the model with MultiOutputClassifier\n",
        "multi_output_gb = MultiOutputClassifier(gb_model)\n",
        "\n",
        "# Train the MultiOutputClassifier model\n",
        "multi_output_gb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_predictions_GB = multi_output_gb.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBc9xr6WJKvd",
        "outputId": "b0b0f22e-7ebd-4260-a309-9e824531f1c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   obsession       0.99      0.92      0.95       578\n",
            "  compulsion       0.98      0.97      0.98      1004\n",
            "\n",
            "   micro avg       0.98      0.95      0.97      1582\n",
            "   macro avg       0.99      0.95      0.97      1582\n",
            "weighted avg       0.99      0.95      0.97      1582\n",
            " samples avg       0.65      0.66      0.65      1582\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "label_names = ['obsession','compulsion']\n",
        "print(classification_report(y_test, y_predictions_GB,target_names=label_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVAyAmAqJsCV",
        "outputId": "b60c41cb-9d06-48a4-a6c2-d3d31347d58e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[[1417    5]\n",
            "  [ 161  417]]\n",
            "\n",
            " [[ 910   86]\n",
            "  [  73  931]]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# Print confusion matrix\n",
        "# Print confusion matrix\n",
        "conf_matrix = multilabel_confusion_matrix(y_test, y_pred_tf)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "#For the 'obsession' class:\n",
        "#True Positive (TP): 511\n",
        "#False Positive (FP): 28\n",
        "#True Negative (TN): 1394\n",
        "#False Negative (FN): 67\n",
        "\n",
        "#For the 'compulsion' class:\n",
        "#True Positive (TP): 968\n",
        "#False Positive (FP): 35\n",
        "#True Negative (TN): 961\n",
        "#False Negative (FN): 36\n",
        "\n",
        "\n",
        "#True Positive (TP): Instances correctly predicted as belonging to the class.\n",
        "#False Positive (FP): Instances incorrectly predicted as belonging to the class (they don't actually belong to it).\n",
        "#True Negative (TN): Instances correctly predicted as not belonging to the class.\n",
        "#False Negative (FN): Instances incorrectly predicted as not belonging to the class (they actually belong to it).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6mHO6BpKZpQ"
      },
      "source": [
        "## NB using tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ocg0MQ2vKDxa"
      },
      "outputs": [],
      "source": [
        "#intialize the Random Forest Model\n",
        "clf_NB = MultiOutputClassifier(MultinomialNB()).fit(X_train_tfidf, y_train)\n",
        "#train the model\n",
        "prediction_NB_tf = clf_NB.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ1l7zp_KD-n",
        "outputId": "abb96f04-10a8-4500-b802-855b071dc91b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   obsession       0.86      0.22      0.35       578\n",
            "  compulsion       0.72      0.87      0.79      1004\n",
            "\n",
            "   micro avg       0.73      0.63      0.68      1582\n",
            "   macro avg       0.79      0.55      0.57      1582\n",
            "weighted avg       0.77      0.63      0.63      1582\n",
            " samples avg       0.47      0.44      0.45      1582\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "label_names = ['obsession','compulsion']\n",
        "print(classification_report(y_test, prediction_NB_tf,target_names=label_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBqKEm_NKEKh",
        "outputId": "f3d24434-85a8-4a60-98a9-1b814c71e81c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[[1402   20]\n",
            "  [ 450  128]]\n",
            "\n",
            " [[ 649  347]\n",
            "  [ 128  876]]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# Print confusion matrix\n",
        "# Print confusion matrix\n",
        "conf_matrix = multilabel_confusion_matrix(y_test, prediction_NB_tf)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "#For the 'obsession' class:\n",
        "#True Positive (TP): 511\n",
        "#False Positive (FP): 28\n",
        "#True Negative (TN): 1394\n",
        "#False Negative (FN): 67\n",
        "\n",
        "#For the 'compulsion' class:\n",
        "#True Positive (TP): 968\n",
        "#False Positive (FP): 35\n",
        "#True Negative (TN): 961\n",
        "#False Negative (FN): 36\n",
        "\n",
        "\n",
        "#True Positive (TP): Instances correctly predicted as belonging to the class.\n",
        "#False Positive (FP): Instances incorrectly predicted as belonging to the class (they don't actually belong to it).\n",
        "#True Negative (TN): Instances correctly predicted as not belonging to the class.\n",
        "#False Negative (FN): Instances incorrectly predicted as not belonging to the class (they actually belong to it).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUsuboRQAjeB",
        "outputId": "e955ff78-71a9-4bf6-807a-b67a80037446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for obsession: 0.765\n",
            "Accuracy for compulsion: 0.7625\n"
          ]
        }
      ],
      "source": [
        "# Assuming y_test and y_pred are your actual and predicted labels\n",
        "label_names = ['obsession', 'compulsion']\n",
        "\n",
        "# Calculate accuracy for each label\n",
        "accuracy_per_label = {label: accuracy_score(y_test[:, i], prediction_NB_tf[:, i]) for i, label in enumerate(label_names)}\n",
        "\n",
        "# Print accuracy for each label\n",
        "for label, acc in accuracy_per_label.items():\n",
        "    print(f'Accuracy for {label}: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1lt0ovAPA98",
        "outputId": "58014906-e2d9-4f3b-8390-8ae989e6afaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6215\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, prediction_NB_tf)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz4RFhv9AzpL"
      },
      "source": [
        "## KNN + tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiiIt1TdA2dq",
        "outputId": "6e14c6f9-9753-4870-9a4e-80caae3a6424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for KNN: 0.314\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Initialize the KNN model with specified parameters\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto')\n",
        "\n",
        "# Train the KNN model\n",
        "knn_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "knn_predictions_tf = knn_model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, knn_predictions_tf)\n",
        "\n",
        "print(f'Accuracy for KNN: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5PmM3KLA2od",
        "outputId": "64b0c9d9-d3f3-4c56-db0f-459e0d300127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   obsession       0.00      0.00      0.00       578\n",
            "  compulsion       0.75      0.00      0.01      1004\n",
            "\n",
            "   micro avg       0.75      0.00      0.00      1582\n",
            "   macro avg       0.38      0.00      0.00      1582\n",
            "weighted avg       0.48      0.00      0.00      1582\n",
            " samples avg       0.00      0.00      0.00      1582\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#classification report\n",
        "label_names = ['obsession','compulsion']\n",
        "print(classification_report(y_test, knn_predictions_tf,target_names=label_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD_yrScMA2tx",
        "outputId": "a2ec36e5-a86a-450d-a601-5f76c7135bb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for obsession: 0.711\n",
            "Accuracy for compulsion: 0.499\n"
          ]
        }
      ],
      "source": [
        "# Assuming y_test and y_pred are your actual and predicted labels\n",
        "label_names = ['obsession', 'compulsion']\n",
        "\n",
        "# Calculate accuracy for each label\n",
        "accuracy_per_label = {label: accuracy_score(y_test[:, i], knn_predictions_tf[:, i]) for i, label in enumerate(label_names)}\n",
        "\n",
        "# Print accuracy for each label\n",
        "for label, acc in accuracy_per_label.items():\n",
        "    print(f'Accuracy for {label}: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AWEx0NWZeoE",
        "outputId": "3ba5913b-2032-4965-f8a7-128f3c212687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[[1422    0]\n",
            "  [ 578    0]]\n",
            "\n",
            " [[ 995    1]\n",
            "  [1001    3]]]\n"
          ]
        }
      ],
      "source": [
        "conf_matrix = multilabel_confusion_matrix(y_test, knn_predictions_tf)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGOCkcleSBh-"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTix7epkSDiG",
        "outputId": "562ec68e-1ccf-45a0-aa13-f2ff5358aaa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix for obsession:\n",
            "[[1421    1]\n",
            " [  97  481]]\n",
            "\n",
            "\n",
            "Confusion Matrix for compulsion:\n",
            "[[867 129]\n",
            " [ 16 988]]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_rf_tf= rf_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "conf_matrix = multilabel_confusion_matrix(y_test, y_pred_rf_tf)\n",
        "\n",
        "# Print confusion matrix for each class\n",
        "for i, label in enumerate(['obsession', 'compulsion']):\n",
        "    print(f\"Confusion Matrix for {label}:\")\n",
        "    print(conf_matrix[i])\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPqD-Ce7SD33",
        "outputId": "41965858-830c-4051-9077-ab7a92f5f36d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   obsession       1.00      0.83      0.91       578\n",
            "  compulsion       0.88      0.98      0.93      1004\n",
            "\n",
            "   micro avg       0.92      0.93      0.92      1582\n",
            "   macro avg       0.94      0.91      0.92      1582\n",
            "weighted avg       0.93      0.93      0.92      1582\n",
            " samples avg       0.63      0.64      0.63      1582\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#classification report\n",
        "label_names = ['obsession','compulsion']\n",
        "print(classification_report(y_test, y_pred_rf_tf,target_names=label_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdRG4M9ZSEJw",
        "outputId": "3fe9b01d-f22d-4a18-ec4f-aefc9bbdbf0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for obsession: 0.951\n",
            "Accuracy for compulsion: 0.9275\n"
          ]
        }
      ],
      "source": [
        "# Assuming y_test and y_pred are your actual and predicted labels\n",
        "label_names = ['obsession', 'compulsion']\n",
        "\n",
        "# Calculate accuracy for each label\n",
        "accuracy_per_label = {label: accuracy_score(y_test[:, i], y_pred_rf_tf[:, i]) for i, label in enumerate(label_names)}\n",
        "\n",
        "# Print accuracy for each label\n",
        "for label, acc in accuracy_per_label.items():\n",
        "    print(f'Accuracy for {label}: {acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZpwcLOD7cEp"
      },
      "source": [
        "## BOW using labeled data and manual label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l7ejUBmUHB8"
      },
      "outputs": [],
      "source": [
        "#Data with negative sample (without annotation)\n",
        "df = pd.read_csv('/content/drive/MyDrive/post classification/processed_data/posts-ontology-manual-label.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzENEGWfVwMl"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc22OIAvgKU2"
      },
      "outputs": [],
      "source": [
        "df['post'] = df['post'].astype(str)\n",
        "df = clean_text(df)\n",
        "df['post'] = df['post'].apply(process_text)\n",
        "#process_df['clean_text'] = process_df['clean_text'].apply(process_text)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HolmsCkamvR"
      },
      "source": [
        "### BOW and LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKWwTWf_UHkL"
      },
      "outputs": [],
      "source": [
        "# Creating features using Bag of Word\n",
        "text_data = df['post'].astype(str)\n",
        "\n",
        "# Convert text to vectors using CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X = count_vect.fit_transform(text_data)\n",
        "\n",
        "# Assuming 'compulsion' and 'obsession' are the target labels\n",
        "Y = np.asarray(df[['compulsion', 'obsession']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxtWBX7zmEKR",
        "outputId": "fd06de5b-0ae2-4c3d-8348-219977d389e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents: 9996\n",
            "Number of unique tokens: 25399\n",
            "(9996, 25399)\n",
            "(9996, 2)\n"
          ]
        }
      ],
      "source": [
        "#devide the data into train and test\n",
        "# Get the shape (size) of the DTM\n",
        "num_documents, num_tokens = X.shape\n",
        "\n",
        "# Print the number of documents and tokens\n",
        "print(\"Number of documents:\", num_documents)\n",
        "print(\"Number of unique tokens:\", num_tokens)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La7Z3954mHMu"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvzfmXdsmmYp",
        "outputId": "c265ef87-2d48-4852-a5a0-fb3d0c7cfbd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7996, 25399)\n",
            "(2000, 25399)\n",
            "(7996, 2)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu1JlerP1NPe",
        "outputId": "9d0a6117-8ca1-4263-9acb-efb05cc910e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.95       499\n",
            "           1       0.95      0.94      0.94       996\n",
            "\n",
            "   micro avg       0.95      0.94      0.95      1495\n",
            "   macro avg       0.96      0.93      0.95      1495\n",
            "weighted avg       0.96      0.94      0.95      1495\n",
            " samples avg       0.61      0.62      0.61      1495\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming X and Y are your features and labels\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Handle NaN values in features using SimpleImputer\n",
        "imputer_features = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer_features.fit_transform(X_train)\n",
        "X_test_imputed = imputer_features.transform(X_test)\n",
        "\n",
        "# Handle NaN values in labels using SimpleImputer\n",
        "imputer_labels = SimpleImputer(strategy='most_frequent')\n",
        "y_train_imputed = imputer_labels.fit_transform(y_train)\n",
        "y_test_imputed = imputer_labels.transform(y_test)\n",
        "\n",
        "# Initialize the logistic regression model\n",
        "clf_LR = MultiOutputClassifier(LogisticRegression())\n",
        "\n",
        "# Fit the model to the training data\n",
        "clf_LR.fit(X_train_imputed, y_train_imputed)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = clf_LR.predict(X_test_imputed)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test_imputed, predictions))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_Y6j9f5NYsIV",
        "_R_yP1UeDqoD",
        "PnBSSHay-FmB",
        "D-vor4Y_TZyH",
        "JxA7uEJ8Hbyn",
        "wuZwTLKgXWhE",
        "CFA6HV7VIGKV",
        "NfrqJY1sItQN",
        "T6mHO6BpKZpQ",
        "rz4RFhv9AzpL",
        "QZpwcLOD7cEp"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
